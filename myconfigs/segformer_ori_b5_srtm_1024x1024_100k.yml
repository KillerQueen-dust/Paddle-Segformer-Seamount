batch_size: 1
iters: 100000

train_dataset:
  type: Dataset
  dataset_root: ../datasets/SRTM/
  train_path: ../datasets/SRTM/train.txt
  num_classes: 2
  img_channels: 1
  mode: train
  transforms:
    - type: ResizeStepScaling
      min_scale_factor: 0.5
      max_scale_factor: 2.0
      scale_step_size: 0.25
    - type: RandomPaddingCrop
      crop_size: [ 1024, 1024 ]
    - type: RandomHorizontalFlip
#    - type: RandomDistort
#      brightness_range: 0.5
#      contrast_range: 0.5
#      saturation_range: 0.5
    - type: NormalizeUint16

val_dataset:
  type: Dataset
  dataset_root: ../datasets/SRTM/
  val_path: ../datasets/SRTM/val.txt
  num_classes: 2
  img_channels: 1
  mode: val
  transforms:
    - type: NormalizeUint16

model:
  type: SegFormer_ori
  backbone:
    type: MixVisionTransformer_B5
    in_channels: 1
#    pretrained: https://bj.bcebos.com/paddleseg/dygraph/backbone/mix_vision_transformer_b5.tar.gz
  embedding_dim: 768
  num_classes: 2

optimizer:
  type: AdamW
  beta1: 0.9
  beta2: 0.999
  weight_decay: 0.01

lr_scheduler:
  type: PolynomialDecay
  learning_rate: 0.00006
  power: 1

loss:
  types:
    - type: CrossEntropyLoss
  coef: [1]


test_config:
  is_slide: True
  crop_size: [ 1024, 1024 ]
  stride: [ 512, 512 ]
